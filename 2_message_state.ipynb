{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b3e424d",
   "metadata": {},
   "source": [
    "### Boilerplate code - llm initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed6bdaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bccb1-b414-7050-9e5e-46f60d6d9d89-0', usage_metadata={'input_tokens': 2, 'output_tokens': 261, 'total_tokens': 263, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 252}})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "google_llm = ChatGoogleGenerativeAI(\n",
    "    temperature=0, \n",
    "    model=\"gemini-2.5-flash\", \n",
    "    api_key=google_api_key,\n",
    "    max_tokens=200\n",
    ")\n",
    "\n",
    "openai_llm = ChatOpenAI(\n",
    "    temperature=0, \n",
    "    model=\"gpt-4\", \n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "google_llm.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002f3e2e",
   "metadata": {},
   "source": [
    "## Message state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2af9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Oh, I'm definitely not angry with you! As an AI, I don't actually have emotions like anger, happiness, or sadness. My responses are based on the information I'm programmed with and the goal of being helpful and informative.\\n\\nIs there anything in particular that made you feel that way? Sometimes text can be misinterpreted without the nuances of tone of voice, but I assure you, I'm here to assist you in a friendly and neutral way.\", additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bccb1-c08d-7830-9a92-b4873af94d76-0', usage_metadata={'input_tokens': 24, 'output_tokens': 257, 'total_tokens': 281, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 161}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [AIMessage(content=\"Hi, there!\"), \n",
    "            HumanMessage(content=\"Hello AI!\"), \n",
    "            AIMessage(content=\"How can i help you?\"), \n",
    "            HumanMessage(content=\"Why are you angry at me?\")\n",
    "        ]\n",
    "\n",
    "google_llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93588e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessageState(TypedDict):\n",
    "    messages: list[AnyMessage] # AIMessage(Role is assistant), HumanMessage(Role is human automatically)\n",
    "\n",
    "class MessageState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47941169",
   "metadata": {},
   "source": [
    "### Intro on add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecbc1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "data1 = [{\"role\": \"human\", \"content\": \"test\"}] # role and content are must keys\n",
    "data2 = [{\"role\": \"ai\", \"content\": \"test2\"}]\n",
    "\n",
    "added_data = add_messages(data1, data2)\n",
    "\n",
    "added_data # similar operation like .extend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97207b5",
   "metadata": {},
   "source": [
    "### Langgraph - Building chatbot with MessageState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892d5605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from IPython.display import display, Image\n",
    "from langchain_core.messages import HumanMessage, AIMessage, AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "\n",
    "class MessagesState(MessagesState):\n",
    "    pass\n",
    "\n",
    "# class MessagesState(TypedDict):\n",
    "#     messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "def chatbot(state: MessagesState):\n",
    "    return {\"messages\": google_llm.invoke(state.get('messages'))}\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "graph.invoke({\"messages\": HumanMessage(content=\"Hello\")}) # HumanMessage can be list of direct as internally it uses add_messages reducer i.e .extend so final will be list anyways\n",
    "graph.invoke({\"messages\": HumanMessage(content=\"What is your name?\")})\n",
    "graph.invoke({\"messages\": HumanMessage(content=\"I want to see you\")}) # returns final state of graph execution\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
